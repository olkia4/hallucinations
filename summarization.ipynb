{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z9k3dVRRY7B"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OQJXCXLTYCx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "wUnz-PciTlsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "RPLuWA9bhI8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "kZbjSUkpVH0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3y9Sr1JNqeB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"xsum\", cache_dir=\"/content/drive/MyDrive/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "guAHHvzupSQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZv-iI7OO69L"
      },
      "outputs": [],
      "source": [
        "texts = dataset[\"document\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QxftL2cW6Zb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "IrB12RC-HAvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf59e10a-d98f-453b-d72e-75514c348197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "OWFo_cgSIdrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "d9CMqBbBFu3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summs = []\n",
        "for i in range(len(texts)):\n",
        "  print(i)\n",
        "  inputs = tokenizer(texts[i], return_tensors=\"pt\", truncation=True).to(device)\n",
        "\n",
        "\n",
        "  summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=20)\n",
        "\n",
        "  summs.append(tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])\n",
        "  torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "OI5eKl1iho91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(summs, \"/content/drive/MyDrive/summs.txt\")"
      ],
      "metadata": {
        "id": "o31wAxTu8jb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}