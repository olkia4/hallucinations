{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z9k3dVRRY7B"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OQJXCXLTYCx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "wUnz-PciTlsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "RPLuWA9bhI8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "kZbjSUkpVH0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3y9Sr1JNqeB"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"xsum\", cache_dir=\"/content/drive/MyDrive/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset[\"train\"]"
      ],
      "metadata": {
        "id": "guAHHvzupSQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZv-iI7OO69L"
      },
      "outputs": [],
      "source": [
        "texts = dataset[\"document\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QxftL2cW6Zb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "ans = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "IrB12RC-HAvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf59e10a-d98f-453b-d72e-75514c348197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "OWFo_cgSIdrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "d9CMqBbBFu3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_embs(texts, version):\n",
        "  ans = []\n",
        "  if (version != -1):\n",
        "    ans = list(torch.load(\"/content/drive/MyDrive/file_train\" +str(version)+\".txt\"))\n",
        "    for i in range(len(ans)):\n",
        "      ans[i] = ans[i].reshape(1, len(ans[i]))\n",
        "  for i in range(version + 1, len(texts)):\n",
        "   print(i)\n",
        "   inputs = tokenizer(texts[i],  return_tensors=\"pt\", truncation=True).to(device)\n",
        "   x = model.forward(**inputs).encoder_last_hidden_state[0]\n",
        "   tmp = []\n",
        "   for j in range(len(x)):\n",
        "     if inputs[\"attention_mask\"][0][j]:\n",
        "       tmp.append(x[j])\n",
        "   ans.append(torch.mean(x, axis=0).cpu().reshape(1, len(x[0])))\n",
        "   torch.cuda.empty_cache()\n",
        "   if i % 10000 == 0:\n",
        "     torch.save(torch.cat(ans), \"/content/drive/MyDrive/file_train\" +str(i)+\".txt\")\n",
        "  return ans\n"
      ],
      "metadata": {
        "id": "GDo22BRmGb5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trains = get_embs(texts, -1)"
      ],
      "metadata": {
        "id": "9BL9NL7LcHae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = torch.cat(ans)"
      ],
      "metadata": {
        "id": "yYpfXpIVsPZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(trains, \"/content/drive/MyDrive/file_train.txt\")"
      ],
      "metadata": {
        "id": "KbpNS7r8tp18"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}